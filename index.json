[{"content":"Supervised learning is a technique that aims to learn a hypothesis function $h$ that fits a behavior observed in the real-world, which is governed by an unknown function $f$.\nTo learn this function, we use a set of example data points composed of inputs (also called features) and outcomes (sometimes called labels). These example data points were sampled from the real world behavior, i.e. from the function $f$, at some time in the past. Our goal is that we can extract knowledge from the past to figure out this behavior on unseen data beforehand. This knowledge extracted from the set of examples is materialized on the $h$ function.\nIn Security, we can imagine some examples where this would be useful, like trying to learn if an HTTP request contains malicious payload or if some set of bytes is a malware or not. However, supervised learning is less often used in Security than in many other domains.\nThis happens because the principles of the supervised learning theory conflicts with the nature of Security, limiting its application. But, by understanding these principles, it is also possible to see how to best apply this technique and how it can maybe useful.\nStationary assumption The most important principle in supervised learning is the stationary assumption. When the data that represents the real world behaviors follows the stationary assumption, it means that predicting the behavior using past example is approximately correctly.\nThe stationary assumption states that the behavior that is being learned don\u0026rsquo;t changeÂ through time. This has some important consequences:\nWe expect that each data point is independent of each other. This is important, because if there were causal effects between data points, then the features of a data point $x_1$, caused by $x_0$, would vary with a probability that is a combination of the probability distribution and the effect of $x_0$, hence the distribution would not remain the same over time, because $x_0$ and $x_1$ would vary in different ways. For example, in a box with 1 blue ball and 2 red balls, the probability of picking a blue ball when drawing the first one from the box is 33% while a red one would be 66%. However, if the first one is indeed blue, then the probability of drawing a red ball as the second one is 100%. The first data point (blue ball draw) changed the probability of the second data point. We expect that each data point is identically distributed, i.e. each data point should be drawn from the same probability distribution. We could learn the shopping behavior using data ranging from Black Friday to New Years, however the users\u0026rsquo; behavior in this time is completed different from the rest of the year, therefore the data used to learn has a different probability distribution than the unseen data on which we are going to make predictions. Any dataset that follows these two characteristics is said to hold the i.i.d assumption (independent and identically distributed). The importance for our training datasets on supervised learning to be i.i.d is because it connects the past to the future, without it, any inference made on the available data would be invalid.\nUnderstand the i.i.d assumption is specially important for Security Machine Learning because it is one of the areas where causality and behavior shifts are most present. So, exactly how this assumption affects our ability to do Supervised Machine Learning?\nCausality Many threat behaviors have causal nature, and therefore we should have a lot of care when preparing our datasets and choosing our validation methods.\nA good example is malware classification, where you could have many samples from various families from different years. Each family generation influences each other, and sometimes they have similar characteristics. A special bad situation that could happen with this is that during splitting of the dataset between training and testing, without taking into account the time relation of the families and samples, then you could end up training the model with future information and testing against past samples. This would produce falsely accurate results that would not generalize in the real-world.\nThere are ways to deal with this, but it depends on the type and strength of the causal relation between the data. For this case, ensuring that the newest malware samples are used for test should be enough.\nBehavior Shift We could create a model to learn a threat behavior like the profile of a botnet, however once we started responding effectively to it, adversaries would adapt and our model would become useless because the new botnets would have a totally different behavior. This would be the case of a change in the probability distribution from which the features are drawn, leading to the break of our assumption.\nLooking to the other side Although causality may be addressed by good data preparation, preventing a model to be become outdated due to behavioral shift is almost impossible. However, this problem isn\u0026rsquo;t a new one in Security, such that one best practices is to instead of trying to detect and block malicious action, defenders should define what a legitimate system behavior looks like and block everything else. This can be summarized as: allow lists are more secure than block lists.\nWe can apply the same philosophy for supervised learning, by modeling profiles of legitimate behavior, which usually are more stable. Then, new data points are classified against these multiple profiles models, finally a meta-classifier is used to choose which one is the best fit or if it\u0026rsquo;s an outlier. This has the ability to catch any new threat behavior that deviates from the know legitimate profiles.\nThis combination of multiple models is called ensemble learning, which has shown to improve models performance, like when comparing a Decision Tree model to a Random Forest one.\nAs a side bonus, since this way of building models does not depend on knowing threat behaviors, it avoids the common problem in mining data for Security that usually produce highly unbalanced datasets. We can train each profile using the true positive data of others profiles as false examples, assuming each profile is mutually exclusive.\nThe main challenge in this approach is that adversaries may try to mimic legitimate profiles, however like the authors of Notos showed, this can be useful sometimes, as in their cases this would imply in adversaries using a more stable network infrastructure that would be easily defeated by static block lists. Therefore, forcing adversaries to mimic a legitimate profile could also reduce their capabilities.\nConclusion In conclusion, supervised learning is a powerful technique that allows us to extract knowledge from past data points to predict future behavior. However, in the Security domain, applying it comes with unique challenges due to the presence of causality and behavior shifts. Understanding the stationary assumption and the importance of having an i.i.d dataset is crucial, because it informs us how to best prepare our datasets, choose our validation methods and, most importantly, what are the best behaviors to be modeled using supervised learning.\nLuckily, by modeling profiles of legitimate behavior, and catching new threat behavior that deviates from known legitimate profiles, we can build intelligent allow lists.\nWhile there are challenges, with proper preparation and understanding, supervised learning can be a valuable tool in Security.\nReferences Notos: Building a Dynamic Reputation System for DNS ","permalink":"https://caioferreira.dev/posts/reflections-supervised-ml/reflections-supervised-learning-in-security/","summary":"Supervised learning is a technique that aims to learn a hypothesis function $h$ that fits a behavior observed in the real-world, which is governed by an unknown function $f$.\nTo learn this function, we use a set of example data points composed of inputs (also called features) and outcomes (sometimes called labels). These example data points were sampled from the real world behavior, i.e. from the function $f$, at some time in the past.","title":"Reflections about Supervised Learning on Security"},{"content":"Quick Summary In this post I will show you what is the debt that we collect with during the software lifecycle, what are its causes and how to pay it back.\nIntroduction Often we are faced with a dilemma in software development: implement the best solution for the feature or delivery it quickly but assuming some workarounds and code smells? Whichever side you choose, will be a cost.\nThis cost is even greater if you work on legacy projects or high changing environments. I am a software engineer @ B2W, the biggest e-commerce on Latin America, and because of its long history, we deal with +6 years legacy applications, in which dozens of developers worked through this time. Sum up the e-commerce environment with its high competitiveness that drives constant changes and new features then you will have a millionaire decision at your hands.\nHence, understating how to manage this cost can be a key asset to achieve a product that has both high quality and a short time to market.\nThe decision cost To understand how to manage the decision cost, we must first learn what cost is. Every decision we make in a software project, not just about best solution vs quick \u0026amp; dirty, incurs in a time cost. Sometimes we cannot take this time and need to target production rather earlier than later. In this situation, we exchange bad code for time. Apply this behavior through time and we get a large debt.\nTherefore, Technical Debt is a metaphor in software development, based on the financial debt, about the accumulation of low-quality code in a project over time.\nExtending the metaphor, we can see financial debt as a resource uptake from some institution, therefore, in the software scope, the resource we borrow is time instead of money and the institution that provides us with this is our code base rather than a bank. Thus, in technical debt calculation, the main amount is the time cost to refactor the codebase to a clean design and the interest represents the extra time that will be taken in the future if the team has to work on the messy code.\nEven more debt Although the best solution vs quick \u0026amp; dirty decision is an excellent example to introduce technical debt, it isn\u0026rsquo;t its only source. As Fowler (2009) points out, this case is just a Prudent and Deliberate debt, where the team is aware of the cost it is incurring and know how to pay it back. But we can have four types of debt in total.\nEach debt type has a source associated with it:\nPrudent \u0026amp; Deliberate - the team know how to build good software and has the opportunity to deliver more product value if they speed up. They analyze the tradeoff and judge that cost/earn ratio is enough to justify the bad code, otherwise delaying the solution. Then, they plan how to refactor the debt and implement it as early as possible. Reckless \u0026amp; Deliberate - the team has the skill to build a well-designed solution but do not has the tools or support to do so. This happens when a team is purposely taking debt but without a plan to repay it or to do so in a code that probably will never change. This scenario is more common on unmotivated teams, legacy projects and due to management pressure for fast delivery instead of a constant and quality delivery. Reckless \u0026amp; Inadvertent - the team doesn\u0026rsquo;t know good design practices and incur on costs due to lack of training, experience, and leadership. Prudent \u0026amp; Inadvertent - it is a common case that after we delivery a feature or project we realize that the best design approach would be other than what we did. This situation is unpredictable and can happen to any team due to lack of domain knowledge, obscure requirements, and technology limitations. Of course, this exploration does not exhaust the possible causes for technical debt but includes the most frequent ones.\nLiving on high debt Since the debt causes can be so many, projects can experience an ever-increasing technical debt, to the point where adding new functionality, fix current bugs and operate the application becomes impossible.\nThis type of scenario can be catastrophic, because while the team lives with this application they will lose agility, will observe an increasing bug count, have loss of motivation, increased stress, long production problems (long living bugs), customer complains and possible single points of failure in case only a few people know how to develop and operate the project.\nWhen an application reaches this point we say that it went into technical bankruptcy.\nHowever, using the right strategies we can make the highlighted curve steeper, leading the actual curve nearest to the idealized curve.\nPaying back In order to avoid that applications achieve high debts or to handle projects already with high debt, we need to build a repayment plan. This can have any sort of effort in order to refactor and pay the time due, but the industry set some strategies that have proven effective.\nTechnical Backlog: each task should have a brief description, the reason that the change is important for the project and which part of the code base must change. Like any other task, we should estimate the effort needed to build a good and clean solution. When estimating the cost, the team should add an interest cost that is directly proportional to the probability of this code to change in the future and hence prioritizing the most costly task. A precise estimation is really difficult but a rudimentary approximation is enough to guide the decisions. With this approach the technical debt becomes visible to all stakeholders and the decision of doing such a task can be made upon effort and future impact. The task cost is easily traceable. Don\u0026rsquo;t mix technical and feature tasks. Refactoring costs included on the feature estimation: explain the costs is necessary since we follow the principle that no feature should be implemented above bad code and therefore this code should be refactored first (Boy Scout Rule). This is a fundamental principle once bad code already incur in interests and adding a new feature using it will increase this interest exponentially, to the point where the cost to work on this code will be so high that will be impossible to make further changes. Besides that, there are two other critic strategies that can be used depending on how high debt the project is in.\nBuffer Tasks: the task has a portion of the team\u0026rsquo;s sprint. It can be used to unplanned refactorings, unforeseen problems, discoveries, etc. To avoid the task to be wasted on non-relevant work members of the team should always propose how they pretend to use the time and discuss with the rest of the team. Clean-up Releases: periodically or in critic scenarios, a team can make releases only with technical refactorings. This strategy is only useful if there is already a refactoring list to be made. Furthermore, the business team should give support as this will probably delay new features. The teams should consider using this when a greater effort is necessary, like in big architectural changes, infrastructural changes, build \u0026amp; deploy, etc. Conclusion Therefore, Technical Debt can be key tool from the product perspective. It allows business people to improve time to market and customer satisfaction with the cost of bad code.\nHowever high debt can bring to huge problems to the project, hence we must strive to be Prudent and Deliberated about our debt, always taking it with a repayment plan together, using all kinds of strategies to keep the debt under control.\nTo achieve this all stakeholders must be aware of the debt\u0026rsquo;s nature and existence and bring the development team together in the decision.\nReferences https://www.infoq.com/presentations/debt-aware-culture https://martinfowler.com/bliki/TechnicalDebtQuadrant.html https://www.infoq.com/minibooks/emag-technical-debt?utm_source=minibooks_about_TechnicalDebt\u0026amp;utm_medium=link\u0026amp;utm_campaign=TechnicalDebt https://books.google.com.br/books?id=pKVFDwAAQBAJ\u0026amp;lpg=PA18\u0026amp;ots=Gc9vC8vf80\u0026amp;dq=Software Quality Assurance Pressman 2014\u0026amp;hl=pt-BR\u0026amp;pg=PA18#v=onepage\u0026amp;q=Software Quality Assurance Pressman 2014\u0026amp;f=false ","permalink":"https://caioferreira.dev/posts/technical-debt/technical-debt-tool/","summary":"Quick Summary In this post I will show you what is the debt that we collect with during the software lifecycle, what are its causes and how to pay it back.\nIntroduction Often we are faced with a dilemma in software development: implement the best solution for the feature or delivery it quickly but assuming some workarounds and code smells? Whichever side you choose, will be a cost.\nThis cost is even greater if you work on legacy projects or high changing environments.","title":"Using Technical Debt as your next Tool"},{"content":" Photo by Annie Spratt on Unsplash\nToday we will try to solve the ambiguity in the concept of state, highlighting the differences in the two main notions about it. The post describes the nature of each one, some use cases and how they fit in the object and functional paradigms.\nIntroduction On the last couple of months, I dove into the topic of State Machines and how we can design UIâs with this concept in order to provide better semantic and predictability to our application. When reading and talking about it often I have to stop and clarify which of the two ideas about state I am referring to:\nthe idea of a collection of data at a point in time the idea of the representation of an entity modeled as a state machine. For the sake of comprehension, we will use state to refer to the first and State to the last.\nRequirements We will use Typescript for our yummy examples so some familiarity with it would be good.\nThe state as a travel bag The first notion we became comfortable with when learning about state in software development is the entity âtravel bagâ. Basically, we see a state as a collection of data in a specific point in time. Throughout the application lifecycle, this data is manipulated and altered in order to reflect the business process. For example:\nclass Pizza { private dough: Dough; // it\u0026#39;s an enum that could be traditional or thin private ingredients: Array\u0026lt;Ingredient\u0026gt;; // entity controls private isBeingnPrepared: boolean; private isBaking: boolean; private baked: boolean; constructor() { this.isBeingnPrepared = true; this.isBaking = false; this.baked = false; } // getters and setters public async bakePizza(): void { const oven = new OvenService(); try { this.isBeingnPrepared = false; this.isBaking = true; await oven.bake(this); this.baked = true; } catch (error) { throw error; } } } From this point on, the pizza state, and hence the application state, has changed, because its data was updated. However, two booleans can be arranged in four different ways, and some of them are invalid states. In the object-oriented paradigm we would avoid this by encapsulating such data in an object and modeling its operations only through methods that guarantee atomic and consistent changes.\nUntil this use case, our model seems to be fine. But, the time comes to implement the next step in the pizzeria flow, the delivery.\nclass Pizza { private dough: Dough; private ingredients: Array\u0026lt;Ingredient\u0026gt;; // entity controls private isBeingnPrepared: boolean; private isBaking: boolean; private baked: boolean; private isBeingDelivered: boolean; private hasBeenDelivered: boolean; constructor() { this.isBeingnPrepared = true; this.isBaking = false; this.baked = false; this.isBeingDelivered = false; this.hasBeenDelivered = false; } // getters and setters // bake behavior public async deliveryPizza() { if (!this.baked) { throw new PizzaNotBakedException(); } const deliveryService = new DevelieryService(); try { this.isBeingnPrepared = false; this.isBeingDelivered = true; await deliveryService.send(this); } catch (error) { throw error; } } public notifyDelivery(wasSuccessful) { if (wasSuccessful) { this.hasBeenDelivered = true; } } } What raises a flag in this code is the use of a guard condition at the start of the delivery function that checks if the pizza is baked. If not, it throws an exception. This seems really simple, and if this were the only condition, it would be fine. But, a pizza could already be left for delivery, as such, we donât want to try to send it again. So, we add another guard condition to our function:\nclass Pizza { private dough: Dough; private ingredients: Array\u0026lt;Ingredient\u0026gt;; // entity controls private isBeingPrepared: boolean; private isBaking: boolean; private baked: boolean; private isBeingDelivered: boolean; private hasBeenDelivered: boolean; // constructor // getters and setters // bake behavior public async deliveryPizza() { if (!this.baked) { throw new PizzaNotBakedException(); } if (this.isBeingDelivered) { throw new PizzaAlreadyLeftException(); } const deliveryService = new DevelieryService(); try { this.isBeingPrepared = false; this.isBeingDelivered = true; await deliveryService.send(this, this.notifyDelivery); } catch (error) { throw error; } } // notify delivery behavior } If we elaborate all the scenarios which a pizza can be, this kind of implementation with lots of branches and conditions expressed by if/else statements grows exponentially. It increases our code cyclomatic complexity and diminishes maintainability as such code is more fragile, harder to read and understand.\nIt gets worse when this kind of conditional start to spread across the code, as in the bake function, which needs to be updated in order to not try to bake it again.\nclass Pizza { private dough: Dough; private ingredients: Array\u0026lt;Ingredient\u0026gt;; // entity controls private isBeingPrepared: boolean; private isBaking: boolean; private baked: boolean; private isBeingDelivered: boolean; private hasBeenDelivered: boolean; // constructor // getters and setters public async bakePizza(): void { if (this.baked) { throw new PizzaAlreadyBakedException(); } const oven = new OvenService(); try { this.isBeingPrepared = false; this.isBaking = true; await oven.bake(this); this.baked = true; } catch (error) { throw error; } } // delivery behavior // notify delivery behavior } Although this kind of design serves several proposes, in special on more simple or data-centric scenarios, in fast evolution and process-centric domains it evolves on a mess of code execution paths and unsynchronized conditionals through different functions.\nThe state as an entity travel bag has a use and it is to carry the associated information to the model. Try to control the behavior of this entity through the same concept ends up overloading it with responsibility and creating a silent trap for our design.\nThe problem faced here is that the application architecture allows for invalid behavior through invalid states, and when it does eventually some use case will expose the bugs created by this freedom. Besides that, this approach takes the system invariants, in this case, the Pizza cooking flow, and scatter then inside many implementation points instead of enforcing them in the design.\nSide note: if you are versed in Algebraic Data Types you can see this as a Product Type with cardinality which tends to infinity.\nRepresentational State Once we have the problem of control the entity information and behavior being done by the same construct, the state, our response could not be more simple: letâs break these responsibilities.\nTherefore, we need a new pattern to handle our entityâs behavior.\nBut, the alternative pattern we propose when designing your application is not at all new. It is the State Pattern, describes in many ancient books about OO. And this books will tell you the same, that the State Pattern seeks to delegate an entity behavior to a specific implementation which is the current State and at the end of the method calculate the entityâs next State, which will now represent the entity, replacing its behaviors implementation on the fly. After all, this pattern is a translation of a state machine to the idiom of the nouns. An alternative implementation for our Pizza example can be as below:\ninterface IPizza { bakePizza(); deliveryPizza(); notifyDelivery(wasSuccessful: boolean); } type Pizza = PreparingPizza | BakedPizza | DeliveringPizza | DeliveredPizza; class PreparingPizza implements IPizza { private dough: Dough; // it is an enum that could be traditional or thin private ingredients: Array\u0026lt;Ingredient\u0026gt;; constructor(dough: Dough, ingredients: Array\u0026lt;Ingredient\u0026gt;) { this.dough = dough; this.ingredients = ingredients; } // setters getDough() { return this.dough; } getIngredients() { return this.ingredients; } public async bakePizza(): Promise\u0026lt;BakedPizza\u0026gt; { const oven = new OvenService(); try { await oven.bake(this); return new BakedPizza(this); } catch (error) { throw error; } } public async deliveryPizza() { throw new PizzaNotReadyForDelivery(); } public notifyDelivery(wasSuccessful) { throw new PizzaNotReadyForDelivery(); } } class BakedPizza implements IPizza { private dough: Dough; private ingredients: Array\u0026lt;Ingredient\u0026gt;; // constructor constructor(pizza: PreparingPizza) { this.dough = pizza.getDough(); this.ingredients = pizza.getIngredients(); } // getters and setters public async bakePizza(): Promise\u0026lt;BakedPizza\u0026gt; { throw new PizzaAlreadyBakedException(); } public async deliveryPizza(): Promise\u0026lt;DeliveringPizza\u0026gt; { const deliveryService = new DevelieryService(); try { await deliveryService.send(this); return new DeliveringPizza(this); } catch (error) { throw error; } } public notifyDelivery(wasSuccessful) { throw new PizzaNotLeftForDeliveryYey(); } } class DeliveringPizza implements IPizza { private dough: Dough; private ingredients: Array\u0026lt;Ingredient\u0026gt;; // constructor // getters and setters public async bakePizza(): Promise\u0026lt;BakedPizza\u0026gt; { throw new PizzaAlreadyBakedException(); } public async deliveryPizza(): Promise\u0026lt;DeliveringPizza\u0026gt; { throw new PizzaAlreadyLeftForDeliveryException(); } public notifyDelivery(wasSuccessful) { if (wasSuccessful) { return new DeliveredPizza(this); } } } class DeliveredPizza implements IPizza { private dough: Dough; private ingredients: Array\u0026lt;Ingredient\u0026gt;; // constructor // getters and setters public async bakePizza(): Promise\u0026lt;BakedPizza\u0026gt; { throw new PizzaAlreadyBakedException(); } public async deliveryPizza(): Promise\u0026lt;DeliveringPizza\u0026gt; { throw new PizzaAlreadyLeftForDeliveryException(); } public notifyDelivery(wasSuccessful) { throw new PizzaAlreadyDeliveredException(); } } With this implementation, we enforce the domain invariants with our type system through the interface and the Pizza union type. With it we gain less cyclomatic complexity since we donât have so many branches in our code and, by design, we donât allow for invalid States to happen. Besides that, each State carries an internal data, its travel bag. As such, these patterns are not excluding, but rather composable.\nIn the trend on the front-end what we are usually seeing is more a functional paradigm approach to the state machines. The entity, represented as a state machine, is now just a different data structure for each State that can be interpreted by the pure functions that implement the domain behaviors. These functions than can internally delegate its call to others functions specialized in each State. This separation of the state machine implementation of the behavior is natural as it follows the idiom for functional architectures.\nWhat remains in both cases are the nature of the State as an entityâs representation. It works on its behalf and delimits the possible behaviors it can expose.\nFor example, a Pizza could never be in Baked and Delivered States at the same time. Now, it isnât an implementation that guarantees that it is the design itself. Such abstractions, that models the domain, the heart of our product, couldnât depend on implementation details to be valid, they must depend on the abstractions itself.\nSide note: if you are versed in Algebraic Data Types you can see this as a Union Type with finite cardinality in the order of less then a dozen.\nEvolving the abstraction One could implement a State oriented design by using a simple enum, a proper state machine implementation or a more advanced concept, a statechart.\nIt is true that many domains can be modeled using the two first approaches to code a State, but sometimes we are faced with a high complexity scenario where this abstraction implementation would not scale with the development of the application.\nFor that reason that in 1987 David Harel proposed a new technique that expanded the grounds of the state machine definition, introducing tools like state hierarchy, parallelism, clustering, history, etc. He called it statecharts and it is a formalism that helps us scale the development of a State design, be implementing it thoroughly or just taking some tools.\nI highly recommend reading more about statecharts as it can shift your mindset about how to approach problems.\nSummary Now we can differentiate state from State and avoid accidental complexity by using the right construct to model our domain. Its worth nothing if I donât say that there is no silver bullet and these are tools to deliver a job. We have been experimenting with this design style on my team and it has been helpful since our scenario is really complex and fast pacing.\nIf you have any questions or want to discuss these and other topics more in deep please comment or you can reach me at Twitter, @caiorcferreira.\nThanks for reading!\nReferences State Design Pattern State Driven Development for User Interfaces A Statechart implementation on JS Statecharts: A Visual Formalism For Complex Systems - the original article Pure UI Control Constructing User Interfaces with Statecharts ","permalink":"https://caioferreira.dev/posts/difference-between-state-and-state/","summary":"Photo by Annie Spratt on Unsplash\nToday we will try to solve the ambiguity in the concept of state, highlighting the differences in the two main notions about it. The post describes the nature of each one, some use cases and how they fit in the object and functional paradigms.\nIntroduction On the last couple of months, I dove into the topic of State Machines and how we can design UIâs with this concept in order to provide better semantic and predictability to our application.","title":"Difference between state and State"}]